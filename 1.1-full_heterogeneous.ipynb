{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":480159,"status":"ok","timestamp":1693955759675,"user":{"displayName":"Honglin Bao","userId":"14286809748787468687"},"user_tz":240},"id":"19qlh6GI5eS8","outputId":"edea1a7c-622c-4586-8f9e-80089d12b2ba"},"outputs":[{"name":"stdout","output_type":"stream","text":["example output: Correlation (citation-quality)\n","0.6821760820824182\n","0.6946558743792031\n","0.7003326350250616\n","0.7047678449551197\n","0.7144567355182033\n","0.7205163622546379\n","0.7251803303226115\n","0.732699326982248\n","0.7399533756046017\n","0.744458695923277\n","0.7511596234884234\n","0.7591530174313806\n","0.759762734292194\n","0.7658497902424874\n","0.7716240698393839\n","0.7765811957481696\n","0.7791930063441965\n","0.7846007585717447\n","0.7901075982137121\n","0.7932092848960715\n","0.7992292988054019\n","0.8023262140724328\n","0.8094982155042949\n","0.8080074929647062\n","0.8123692404650247\n","0.8163709283130114\n","0.8140631329729043\n","0.8226628527716389\n","0.8263174916111032\n","0.8297288861291215\n","0.8312781483483817\n","0.8335037329842886\n","0.8366503584349445\n","0.8417526604640728\n","0.8443912573831787\n","0.8482489057942555\n","0.8526061848533057\n","0.8518112744935851\n","0.8533511709332505\n","0.8589179926767286\n","0.8616010243401881\n","0.8633714528720305\n","0.8673879969807818\n","0.8693491396242791\n","0.8716830097725926\n","0.8727026528781944\n","0.8752561172188099\n","0.87826200641997\n","0.8781568522533423\n","0.8832817349036889\n","0.8859999063997211\n","0.8839250603709498\n","0.8831871269092205\n","0.8902309259544778\n","0.8899859055756767\n","0.8941178967915494\n","0.895162053428971\n","0.8967076185224436\n","0.8963531326990178\n","0.8976023722144711\n","0.902860047699306\n","0.9012398073606347\n","0.9012073728508789\n","0.9043125751197566\n","0.9082303853671095\n","0.9092751401451201\n","0.9099050367957702\n","0.9105958472900765\n","0.9113551111618797\n","0.9119627250320539\n","0.9137599214453297\n","0.9147982063581852\n","0.9154552154846419\n","0.916873635602039\n","0.9176985609603625\n","0.918813637922048\n","0.9190348070358608\n","0.9181924647305078\n","0.9212779208496875\n","0.920772281982779\n","0.9226390918138277\n","Note: the full model's correlation is higher than either null models, but the null models are in different notebooks\n"]}],"source":["#heterogeneous quality + heterogeneous rhetorical value full model\n","# note: in the paper, we run the code below 20 times for each set of\n","# (literature size, reading budget, reference budget) values.\n","#The code/result here is for 1 run.\n","\n","import random\n","import numpy as np\n","random.seed(100000)\n","np.random.seed(100000)\n","#fix random seeds across six models to make results exactly reproducible\n","#average across 20 fixed-seed runs and get average effects/error bands, etc.\n","#this is because we want to ensure that\n","#observed differences between models\n","#are due to the mechanisms we proposed and not random variations between comparison experiments\n","\n","import scipy.stats as stats\n","from scipy.stats import pearsonr\n","from scipy.stats import norm\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","#helper function for calculating Gini coefficient\n","def gini_coefficient(x):\n","    \"\"\"Compute Gini coefficient of array of values\"\"\"\n","    diffsum = 0\n","    for i, xi in enumerate(x[:-1], 1):\n","        diffsum += np.sum(np.abs(xi - x[i:]))\n","    return diffsum / (len(x)**2 * np.mean(x))\n","\n","#helper function for getting indices of the top N values of a list (which to read/cite)\n","def f(a,N):\n","    \"\"\"Get indices of the top N values of a list\"\"\"\n","    return np.argsort(a)[::-1][:N]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# THIS SECTION DETERMINES WHICH PARAMETER WILL VARY (literature size, reference budget, or reading budget).\n","# To choose which parameter to vary, change the min and max values accordingly. Currently, the code is set to\n","# vary the reference budget.\n","\n","tmax= 1000 #time steps\n","#-----------------------------\n","num = 600 # literature size min\n","nummax=600 # literature size max\n","#-----------------------------\n","reference = 20 # reference budget min\n","refmax =100  # reference budget max\n","#-----------------------------\n","reading = 120 # reading budget min\n","readingmax=120 # reading budget max\n","#-----------------------------\n","noise =0.05 #tested for robustness (see Appendix 1.3)\n","fit =0.1 #tested for robustness (see Appendix 1.4)\n","shape =6 #shape for distributions of underlying initial rhetorical value and base quality, tested for robustness (see Appendix 1.1)\n","#-----------------------------------------------------------------\n","\n","# OUTCOMES\n","listcorr=[] #correlation (citation-quality)\n","listgini=[] #gini\n","#figure 2, in what way top-quality/mid-quality papers are cited? (substantive or rhetorical)\n","list1=[] #top papers cited substantively\n","list2=[] #top papers cited rhetorically\n","list3=[] #mid papers cited substantively\n","list4=[] #mid papers cited rhetorically\n","\n","for num in range(num, nummax+1): # varying literature size\n","  normative=np.random.beta(1, shape, size=num)\n","  qrank =[]\n","  qrank = list(np.argsort(normative)[-(num):][::-1]) #quality distribution and its rank\n","  weight=0.001 #the weight of citation count on perceived quality\n","  weightq =0.3#the perceived quality signal-based gain in rhetoric value\n","  #tested for robustness (see Appendix 1.5: reinforcing process)\n","\n","  for reference in range(reference, refmax+1):   # comment if want to fix reference budget\n","  #for reading in range(reading, readingmax+1):  # uncomment if want to vary reading budget\n","\n","    top1q=qrank[0:40]# top 40 quality (high quality)\n","    top2q=qrank[40:int(150)]# top 40-150 quality (mid-to-high quality) /600 in total\n","\n","    cite_population = [0]*num #citation count over the entire paper population, initial as 0\n","    rhe_list=[0]*num #rhetoric value, initial as 0\n","    chunk =[] #citation churn\n","\n","    for t in range(1, tmax+1): #a reader joins\n","    #heterogeneous quality: the reader has her own perception of--\n","    #--threshold/fit/error/underlying rhetorical value\n","    #initialize them within the loop\n","\n","      threshold =random.uniform(0,1)\n","      #normal distribution of threshold for robustness\n","      #we tested robustness (see Appendix 1.2)\n","      #mu, sigma = 0.5, 0.2\n","      #lower, upper = 0, 1\n","      #X1 = stats.truncnorm(\n","      #  (lower - mu) / sigma, (upper - mu) / sigma, loc=mu, scale=sigma)\n","      #threshold1=X1.rvs(1)\n","      #threshold =threshold1[0]\n","\n","      #underlying rhetorical value is heterogeneous\n","      base_rhe=np.random.beta(1, shape, size=num)\n","\n","      noise_list=np.random.normal(0, noise, num)\n","      #we tested it for robustness (see Appendix 1.3)\n","\n","      #fit - heterogeneous\n","      fit_list=[]\n","      for i in range(num):\n","        fit_list.append(random.uniform(-fit, fit))\n","      #tested for robustness (see Appendix 1.4)\n","\n","      # quality + fit + perception error, needs to be truncated to [0, 1]\n","      pq =[]\n","      for i in range(num):\n","        #0-1 cut off\n","        pq.append(normative[i]+ fit_list[i] + noise_list[i])\n","      for i in range(num):\n","        if (pq[i] >1): #maximum 1, quality +fit +error =1\n","          pq[i] =1\n","        if (pq[i] <0):\n","          pq[i] =0 #non-negative\n","\n","      # perceived quality signal (quality + fit + perception error + citation premium)\n","      signal =[]\n","      for i in range(num):\n","        signal.append(pq[i] + weight * cite_population[i] )\n","\n","      # the conditions below ensure that perceived quality signal is within [0, 2]\n","      # but given the constituent parts it should never be outside of that anyway\n","      for i in range(num):\n","        if (signal[i] >2): #maximum 2, quality +fit +error =1, weight * citation (citation premium) =1\n","          signal[i] =2\n","        if (signal[i] <0):\n","          signal[i] =0 #non-negative\n","\n","      #read papers with the highest perceived quality\n","      reading_index = list(np.argsort(signal)[-(reading):][::-1])\n","\n","      # CALCULATE OVERALL RHETORICAL VALUE\n","      # rhetorical value = base rhetorical value + beta*perceived quality\n","      # but perceived quality should be adjusted if paper is read (i.e., perception error removed)\n","      # If read...\n","      #PAPER IS READ:\n","      # remove perception noise from the rhetorical value of *read* papers (since their quality has been observed)\n","      for i in range(len(reading_index)):\n","        rhe_list[reading_index[i]] =base_rhe[reading_index[i]] + weightq* (pq[reading_index[i]] -noise_list[reading_index[i]] ) + weightq* weight*cite_population[reading_index[i]]\n","\n","      # If unread...\n","      unread=[]\n","      unread = [i for i in list(range(0,num)) if i not in reading_index]\n","      for i in range(len(unread)):\n","        rhe_list[unread[i]] =base_rhe[unread[i]] + weightq* pq[unread[i]]+ weightq* weight*cite_population[unread[i]]\n","\n","      # truncate rhetorical values to [0, 1+2*beta]\n","      # but given the constituent parts it should never be outside of that anyway\n","      for i in range(num):\n","        if (rhe_list[i] <0):\n","          rhe_list[i] =0\n","        if(rhe_list[i] > 1+ weightq+ weightq):\n","          rhe_list[i] =1+ weightq+ weightq\n","\n","      # perceived quality: after reading, the error disappears, so perceived quality = quality + fit\n","      norm_list =[]\n","      for i in range(len(reading_index)):\n","        norm_list.append(normative[reading_index[i]] + fit_list[reading_index[i]])\n","\n","      # truncate perceived quality to [0, 1]\n","      # the idea behind all truncations is that\n","      # fit or perception error can make a paper perfect (perceived quality close to 1) in people's eyes\n","      # but they cannot make an already perfect one exceed the range\n","      for i in range(len(reading_index)):\n","        if (norm_list[i] <0):\n","          norm_list[i] =0\n","        if (norm_list[i] >1):\n","          norm_list[i] =1\n","\n","      #which paper is above the substantive citing threshold?\n","      over_threshold=[]\n","      for i in range(len(norm_list)):\n","        if (norm_list[i]> threshold):\n","          over_threshold.append(reading_index[i])\n","\n","      normative_cite=[]# substantive citation list\n","      rhetorical_cite=[]# rhetorical citation list\n","      overlap=[]#overlap between substantive and rhetorical citing\n","      overall_cite =[]\n","\n","      #if there are enough good papers for substantive citing\n","      #then all cites are substantive (cite the best ones within the citing budget)\n","      #update citation counts -- and the impact that citations induce\n","      if (len(over_threshold) >= reference):\n","        cite = list(f(norm_list, reference))\n","        for i in range(len(cite)):\n","          cite_population[reading_index[cite[i]]]= cite_population[reading_index[cite[i]]]+1\n","          normative_cite.append(reading_index[cite[i]])\n","        rhetorical_cite=[]\n","        overlap =[]\n","        overall_cite = normative_cite + rhetorical_cite + overlap\n","\n","      #if there are insufficiently many good papers for substantive citing\n","      #first, cite all of these good ones substantively as \"normative_cite\"\n","      else:\n","        normative_cite = over_threshold.copy()\n","        #how many slots are left -- we fill up all of the rest slots according to the overall rhetorical values\n","        rhetoric_no = reference - len(over_threshold)\n","        new_rhe = rhe_list.copy()\n","        rhe2=[]\n","        rhe2 = sorted(new_rhe, reverse = True)\n","        itr=0\n","        itr2=0\n","        while (itr < rhetoric_no):\n","          # a small proportion of papers first is cited substantively\n","          # then if people find them rhetorically useful as well\n","          # move them into the set of \"overlap\" --\n","          # cited both substantively and rhetorically (we allow this which is the case in the real world)\n","\n","          if ((new_rhe.index(rhe2[itr2]) in normative_cite) == True):\n","            normative_cite.remove(new_rhe.index(rhe2[itr2]))\n","            numitr = new_rhe.index(rhe2[itr2])\n","            overlap.append(numitr)\n","            itr2 =itr2+1\n","          else:\n","            rhetorical_cite.append(new_rhe.index(rhe2[itr2]))\n","            itr =itr+1\n","            itr2 =itr2+1\n","\n","        #update citation count\n","        overall_cite = normative_cite + rhetorical_cite + overlap\n","        for i in range(len(overall_cite)):\n","          cite_population[overall_cite[i]] = cite_population[overall_cite[i]] +1\n","      #churn\n","      #this round, which papers get cited?\n","      chunk.append(overall_cite)\n","\n","# SUB-ANALYSIS\n","# track outcomes for 2 types of papers {high quality, mid quality}\n","# and 2 types of citations {substantive, rhetorical}, see Figure 2\n","      #top1=0\n","      #for i in range(40):\n","      # if ((top1q[i] in (normative_cite + overlap)) == True):\n","      #    top1 = top1+1\n","      #list1.append(top1/reference)\n","      #top2=0\n","      #for i in range(40):\n","      #  if ((top1q[i] in (rhetorical_cite + overlap)) == True):\n","      #    top2 = top2+1\n","      #list2.append(top2/reference)\n","      #top3=0\n","      #for i in range(110):\n","      #  if ((top2q[i] in (normative_cite + overlap)) == True):\n","      #    top3 = top3+1\n","      #list3.append(top3/reference)\n","      #top4=0\n","      #for i in range(110):\n","      #   if ((top2q[i] in (rhetorical_cite + overlap)) == True):\n","      #    top4 = top4+1\n","      #list4.append(top4/reference)\n","\n","    #print(*cite_population, sep='\\n') #every round the citation count distribution\n","\n","    #listgini.append(gini_coefficient(np.array(cite_population))) #gini coefficient\n","\n","    corr1, _ = stats.pearsonr(normative, cite_population)\n","    listcorr.append(corr1) #citation-quality correlation, example output\n","\n","    # churn, which is the newly cited papers compared to the last round\n","    #dnew=[]\n","    #for i in range(len(chunk) -1):\n","    #  a=0\n","     # for j in range(len(chunk[i+1])):\n","     #   if ((chunk[i+1][j] in chunk[i]) == False):\n","     #     a=a+1\n","      #dnew.append(a)\n","    #print(np.mean(dnew))\n","\n","#print(list1)\n","#print(list2)\n","#print(list3)\n","#print(list4)\n","print('example output: Correlation (citation-quality)')\n","print(*listcorr, sep='\\n')\n","print('Note: the full model\\'s correlation is higher than either null models, but the null models are in different notebooks')\n","#print(listgini)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
