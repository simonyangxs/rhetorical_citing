{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":480159,"status":"ok","timestamp":1693955759675,"user":{"displayName":"Honglin Bao","userId":"14286809748787468687"},"user_tz":240},"id":"19qlh6GI5eS8","outputId":"edea1a7c-622c-4586-8f9e-80089d12b2ba"},"outputs":[{"name":"stderr","output_type":"stream","text":["d:\\Program\\anaconda\\lib\\site-packages\\scipy\\__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.2)\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"]}],"source":["#heterogeneous quality + heterogeneous rhetorical value full model\n","# note: in the paper, we run the code below 20 times for each set of\n","# (literature size, reading budget, reference budget) values.\n","#The code/result here is for 1 run.\n","\n","import random\n","import numpy as np\n","random.seed(100000)\n","np.random.seed(100000)\n","#fix random seeds across six models to make results exactly reproducible\n","#average across 20 fixed-seed runs and get average effects/error bands, etc.\n","#this is because we want to ensure that\n","#observed differences between models\n","#are due to the mechanisms we proposed and not random variations between comparison experiments\n","\n","import scipy.stats as stats\n","from scipy.stats import pearsonr\n","from scipy.stats import norm\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["\n","#helper function for calculating Gini coefficient\n","def gini_coefficient(x):\n","    \"\"\"Compute Gini coefficient of array of values\"\"\"\n","    diffsum = 0\n","    for i, xi in enumerate(x[:-1], 1):\n","        diffsum += np.sum(np.abs(xi - x[i:]))\n","    return diffsum / (len(x)**2 * np.mean(x))\n","\n","#helper function for getting indices of the top N values of a list (which to read/cite)\n","def f(a,N):\n","    \"\"\"Get indices of the top N values of a list\"\"\"\n","    return np.argsort(a)[::-1][:N]"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["# THIS SECTION DETERMINES WHICH PARAMETER WILL VARY (literature size, reference budget, or reading budget).\n","# To choose which parameter to vary, change the min and max values accordingly. Currently, the code is set to\n","# vary the reference budget.\n","\n","tmax= 100 #time steps\n","#-----------------------------\n","num = 600 # literature size min\n","nummax=600 # literature size max\n","#-----------------------------\n","reference = 100 # reference budget min\n","refmax =100  # reference budget max\n","#-----------------------------\n","reading = 120 # reading budget min\n","readingmax=120 # reading budget max\n","#-----------------------------\n","noise =0.05 #tested for robustness (see Appendix 1.3)\n","fit =0.1 #tested for robustness (see Appendix 1.4)\n","shape =6 #shape for distributions of underlying initial rhetorical value and base quality, tested for robustness (see Appendix 1.1)\n","#-----------------------------------------------------------------\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# OUTCOMES\n","listcorr=[] #correlation (citation-quality)\n","listgini=[] #gini\n","#figure 2, in what way top-quality/mid-quality papers are cited? (substantive or rhetorical)\n","list1=[] #top papers cited substantively\n","list2=[] #top papers cited rhetorically\n","list3=[] #mid papers cited substantively\n","list4=[] #mid papers cited rhetorically\n"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00,  2.49it/s]"]},{"name":"stdout","output_type":"stream","text":["69.70707070707071\n","example output: Correlation (citation-quality)\n","0.9134441681116476\n","0.911429806469696\n","Note: the full model's correlation is higher than either null models, but the null models are in different notebooks\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["import tqdm as tq\n","for num in range(num, nummax+1): # varying literature size\n","  normative=np.random.beta(1, shape, size=num)   #控制 qi的\n","  qrank =[]\n","  qrank = list(np.argsort(normative)[-(num):][::-1]) # 最好的在前面    quality distribution and its rank\n","  weight=0.001 #the weight of citation count on perceived quality\n","  weightq =0.3#the perceived quality signal-based gain in rhetoric value\n","  #tested for robustness (see Appendix 1.5: reinforcing process)\n","\n","  for reference in tq.tqdm(range(reference, refmax+1)):   # comment if want to fix reference budget\n","  #for reading in range(reading, readingmax+1):  # uncomment if want to vary reading budget\n","\n","    top1q=qrank[0:40]# top 40 quality (high quality)\n","    top2q=qrank[40:int(150)]# top 40-150 quality (mid-to-high quality) /600 in total\n","\n","    cite_population = [0]*num #citation count over the entire paper population, initial as 0\n","    rhe_list=[0]*num #rhetoric value, initial as 0\n","    chunk =[] #citation churn\n","\n","    for t in range(1, tmax+1): #a reader joins\n","    #heterogeneous quality: the reader has her own perception of--\n","    #--threshold/fit/error/underlying rhetorical value\n","    #initialize them within the loop\n","\n","      threshold =random.uniform(0,1)\n","      #normal distribution of threshold for robustness\n","      #we tested robustness (see Appendix 1.2)\n","      #mu, sigma = 0.5, 0.2\n","      #lower, upper = 0, 1\n","      #X1 = stats.truncnorm(\n","      #  (lower - mu) / sigma, (upper - mu) / sigma, loc=mu, scale=sigma)\n","      #threshold1=X1.rvs(1)\n","      #threshold =threshold1[0]\n","\n","      #underlying rhetorical value is heterogeneous\n","      base_rhe=np.random.beta(1, shape, size=num)\n","\n","      noise_list=np.random.normal(0, noise, num)\n","      #we tested it for robustness (see Appendix 1.3)\n","\n","      #fit - heterogeneous\n","      fit_list=[]\n","      for i in range(num):\n","        fit_list.append(random.uniform(-fit, fit))\n","      #tested for robustness (see Appendix 1.4)\n","\n","      # quality + fit + perception error, needs to be truncated to [0, 1]\n","      pq =[]\n","      for i in range(num):\n","        #0-1 cut off\n","        pq.append(normative[i]+ fit_list[i] + noise_list[i])\n","      for i in range(num):\n","        if (pq[i] >1): #maximum 1, quality +fit +error =1\n","          pq[i] =1\n","        if (pq[i] <0):\n","          pq[i] =0 #non-negative\n","\n","      # perceived quality signal (quality + fit + perception error + citation premium)\n","      signal =[]\n","      for i in range(num):\n","        signal.append(pq[i] + weight * cite_population[i] )\n","\n","      # the conditions below ensure that perceived quality signal is within [0, 2]\n","      # but given the constituent parts it should never be outside of that anyway\n","      for i in range(num):\n","        if (signal[i] >2): #maximum 2, quality +fit +error =1, weight * citation (citation premium) =1\n","          signal[i] =2\n","        if (signal[i] <0):\n","          signal[i] =0 #non-negative\n","\n","      #read papers with the highest perceived quality\n","      reading_index = list(np.argsort(signal)[-(reading):][::-1])\n","\n","      # CALCULATE OVERALL RHETORICAL VALUE\n","      # rhetorical value = base rhetorical value + beta*perceived quality\n","      # but perceived quality should be adjusted if paper is read (i.e., perception error removed)\n","      # If read...\n","      #PAPER IS READ:\n","      # remove perception noise from the rhetorical value of *read* papers (since their quality has been observed)\n","      for i in range(len(reading_index)):\n","        rhe_list[reading_index[i]] =base_rhe[reading_index[i]] + weightq* (pq[reading_index[i]] -noise_list[reading_index[i]] ) + weightq* weight*cite_population[reading_index[i]]\n","\n","      # If unread...\n","      unread=[]\n","      unread = [i for i in list(range(0,num)) if i not in reading_index]\n","      for i in range(len(unread)):\n","        rhe_list[unread[i]] =base_rhe[unread[i]] + weightq* pq[unread[i]]+ weightq* weight*cite_population[unread[i]]\n","\n","      # truncate rhetorical values to [0, 1+2*beta]\n","      # but given the constituent parts it should never be outside of that anyway\n","      for i in range(num):\n","        if (rhe_list[i] <0):\n","          rhe_list[i] =0\n","        if(rhe_list[i] > 1+ weightq+ weightq):\n","          rhe_list[i] =1+ weightq+ weightq\n","\n","      # perceived quality: after reading, the error disappears, so perceived quality = quality + fit\n","      norm_list =[]\n","      for i in range(len(reading_index)):\n","        norm_list.append(normative[reading_index[i]] + fit_list[reading_index[i]])\n","\n","      # truncate perceived quality to [0, 1]\n","      # the idea behind all truncations is that\n","      # fit or perception error can make a paper perfect (perceived quality close to 1) in people's eyes\n","      # but they cannot make an already perfect one exceed the range\n","      for i in range(len(reading_index)):\n","        if (norm_list[i] <0):\n","          norm_list[i] =0\n","        if (norm_list[i] >1):\n","          norm_list[i] =1\n","\n","      #which paper is above the substantive citing threshold?\n","      over_threshold=[]\n","      for i in range(len(norm_list)):\n","        if (norm_list[i]> threshold):\n","          over_threshold.append(reading_index[i])\n","\n","      normative_cite=[]# substantive citation list\n","      rhetorical_cite=[]# rhetorical citation list\n","      overlap=[]#overlap between substantive and rhetorical citing\n","      overall_cite =[]\n","\n","      #if there are enough good papers for substantive citing\n","      #then all cites are substantive (cite the best ones within the citing budget)\n","      #update citation counts -- and the impact that citations induce\n","      if (len(over_threshold) >= reference):\n","        cite = list(f(norm_list, reference)) #获得前reference的最大的数\n","        for i in range(len(cite)):\n","          cite_population[reading_index[cite[i]]]= cite_population[reading_index[cite[i]]]+1\n","          normative_cite.append(reading_index[cite[i]])\n","        rhetorical_cite=[]\n","        overlap =[]\n","        overall_cite = normative_cite + rhetorical_cite + overlap\n","\n","      #if there are insufficiently many good papers for substantive citing\n","      #first, cite all of these good ones substantively as \"normative_cite\"\n","      else:\n","        normative_cite = over_threshold.copy()\n","        #how many slots are left -- we fill up all of the rest slots according to the overall rhetorical values\n","        rhetoric_no = reference - len(over_threshold)\n","        new_rhe = rhe_list.copy()\n","        rhe2=[]\n","        rhe2 = sorted(new_rhe, reverse = True)\n","        itr=0\n","        itr2=0\n","        while (itr < rhetoric_no):\n","          # a small proportion of papers first is cited substantively\n","          # then if people find them rhetorically useful as well\n","          # move them into the set of \"overlap\" --\n","          # cited both substantively and rhetorically (we allow this which is the case in the real world)\n","\n","          if ((new_rhe.index(rhe2[itr2]) in normative_cite) == True):\n","            normative_cite.remove(new_rhe.index(rhe2[itr2]))\n","            numitr = new_rhe.index(rhe2[itr2])\n","            overlap.append(numitr)\n","            itr2 =itr2+1\n","          else:\n","            rhetorical_cite.append(new_rhe.index(rhe2[itr2]))\n","            itr =itr+1\n","            itr2 =itr2+1\n","\n","        #update citation count\n","        overall_cite = normative_cite + rhetorical_cite + overlap\n","        for i in range(len(overall_cite)):\n","          cite_population[overall_cite[i]] = cite_population[overall_cite[i]] +1\n","      #churn\n","      #this round, which papers get cited?\n","      chunk.append(overall_cite)\n","\n","# SUB-ANALYSIS\n","# track outcomes for 2 types of papers {high quality, mid quality}\n","# and 2 types of citations {substantive, rhetorical}, see Figure 2\n","      #top1=0\n","      #for i in range(40):\n","      # if ((top1q[i] in (normative_cite + overlap)) == True):\n","      #    top1 = top1+1\n","      #list1.append(top1/reference)\n","      #top2=0\n","      #for i in range(40):\n","      #  if ((top1q[i] in (rhetorical_cite + overlap)) == True):\n","      #    top2 = top2+1\n","      #list2.append(top2/reference)\n","      #top3=0\n","      #for i in range(110):\n","      #  if ((top2q[i] in (normative_cite + overlap)) == True):\n","      #    top3 = top3+1\n","      #list3.append(top3/reference)\n","      #top4=0\n","      #for i in range(110):\n","      #   if ((top2q[i] in (rhetorical_cite + overlap)) == True):\n","      #    top4 = top4+1\n","      #list4.append(top4/reference)\n","\n","    #print(*cite_population, sep='\\n') #every round the citation count distribution\n","\n","    #listgini.append(gini_coefficient(np.array(cite_population))) #gini coefficient\n","\n","    corr1, _ = stats.pearsonr(normative, cite_population)\n","    listcorr.append(corr1) #citation-quality correlation, example output\n","\n","    # churn, which is the newly cited papers compared to the last round\n","    dnew=[]\n","    for i in range(len(chunk) -1):\n","      a=0\n","      for j in range(len(chunk[i+1])):\n","       if ((chunk[i+1][j] in chunk[i]) == False):\n","         a=a+1\n","      dnew.append(a)\n","    print(np.mean(dnew))\n","\n","#print(list1)\n","#print(list2)\n","#print(list3)\n","#print(list4)\n","print('example output: Correlation (citation-quality)')\n","print(*listcorr, sep='\\n')\n","print('Note: the full model\\'s correlation is higher than either null models, but the null models are in different notebooks')\n","#print(listgini)"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"data":{"text/plain":["100"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["len(list(f(norm_list, reference)))"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/plain":["100"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["reference"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"data":{"text/plain":["[2]"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["list(f([1,2,3], 1))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":0}
